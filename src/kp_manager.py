import json
import os
from typing import List, Dict, Any, Optional
from collections import defaultdict

class KnowledgePointManager:
    """
    çŸ¥è¯†ç‚¹ç®¡ç†å™¨ç±» (é‡æ„ç‰ˆ)ã€‚
    æ”¯æŒå¤šç§å¯¼å…¥æ¨¡å¼ã€‚
    """

    def __init__(self, db_path: str):
        self.db_path = db_path
        self.kps: List[Dict[str, Any]] = []
        self.kp_index: Dict[str, Dict[str, Any]] = {}
        self._load_data()

    def _load_data(self):
        if not os.path.exists(self.db_path):
            with open(self.db_path, 'w', encoding='utf-8') as f:
                json.dump([], f)

        try:
            with open(self.db_path, 'r', encoding='utf-8') as f:
                content = f.read()
                self.kps = json.loads(content) if content else []
        except json.JSONDecodeError:
            raise ValueError(f"æ— æ³•è§£æ JSON æ–‡ä»¶: {self.db_path}")

        self._build_index()

    def _build_index(self):
        self.kp_index = {kp['kpid']: kp for kp in self.kps}

    def _save_database(self):
        """å°†å½“å‰å†…å­˜ä¸­çš„çŸ¥è¯†ç‚¹æ•°æ®å†™å…¥åˆ° JSON æ–‡ä»¶ä¸­ã€‚"""
        try:
            with open(self.db_path, 'w', encoding='utf-8') as f:
                json.dump(self.kps, f, ensure_ascii=False, indent=2)
        except IOError as e:
            raise IOError(f"å†™å…¥æ•°æ®åº“æ–‡ä»¶ '{self.db_path}' å¤±è´¥: {e}")

    def get_kp_by_id(self, kpid: str) -> Optional[Dict[str, Any]]:
        return self.kp_index.get(kpid)

    def print_outline(self):
        print("===== çŸ¥è¯†ç‚¹å¤§çº² (æ ‘çŠ¶å›¾) =====")
        if not self.kps:
            print("çŸ¥è¯†ç‚¹åº“ä¸ºç©ºã€‚")
            print("================================")
            return

        children_map = defaultdict(list)
        for kp in self.kps:
            children_map[kp.get('parentId')].append(kp)

        def _print_recursive(parent_id: Optional[str], prefix: str):
            children = sorted(children_map.get(parent_id, []), key=lambda x: x['kpid'])
            for i, child in enumerate(children):
                is_last = i == len(children) - 1
                connector = "â””â”€ " if is_last else "â”œâ”€ "
                display_text = child.get('title') or child.get('content', '')
                short_text = (display_text[:40] + '...') if len(display_text) > 40 else display_text
                print(f"{prefix}{connector}[{child.get('type', 'N/A')}] {child['kpid']} - {short_text}")
                new_prefix = prefix + ("    " if is_last else "â”‚   ")
                _print_recursive(child['kpid'], new_prefix)

        _print_recursive(None, "")
        print("================================")

    def get_ancestry(self, kpid: str) -> List[Dict[str, Any]]:
        ancestry = []
        current_kp = self.get_kp_by_id(kpid)
        while current_kp:
            ancestry.append(current_kp)
            parent_id = current_kp.get('parentId')
            if parent_id:
                current_kp = self.get_kp_by_id(parent_id)
            else:
                break
        return list(reversed(ancestry))

    # --- é‡æ„åçš„å¯¼å…¥æ–¹æ³• ---
    def import_from_file(self, filepath: str, mode: str = 'merge') -> Dict[str, int]:
        """
        ä»JSONæ–‡ä»¶å¯¼å…¥çŸ¥è¯†ç‚¹ä½“ç³»ï¼Œæ”¯æŒå¤šç§å¯¼å…¥æ¨¡å¼ã€‚

        Args:
            filepath: æ–°çŸ¥è¯†ç‚¹ä½“ç³»çš„JSONæ–‡ä»¶è·¯å¾„ã€‚
            mode: å¯¼å…¥æ¨¡å¼ ('replace', 'append', 'merge')ã€‚

        Returns:
            ä¸€ä¸ªåŒ…å«æ“ä½œæ‘˜è¦çš„å­—å…¸, e.g., {'added': 10, 'updated': 5, 'skipped': 3, 'total': 28}
        """
        # 1. è¯»å–å¹¶éªŒè¯æ–°æ–‡ä»¶
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                new_kps = json.load(f)
        except Exception as e:
            raise ValueError(f"è¯»å–æˆ–è§£ææ–‡ä»¶ '{filepath}' å¤±è´¥: {e}")

        if not isinstance(new_kps, list):
            raise TypeError("å¯¼å…¥å¤±è´¥: æ–‡ä»¶å†…å®¹å¿…é¡»æ˜¯ä¸€ä¸ªJSONå¯¹è±¡åˆ—è¡¨ã€‚")

        summary = {'added': 0, 'updated': 0, 'skipped': 0}

        # 2. æ ¹æ®æ¨¡å¼æ‰§è¡Œé€»è¾‘
        if mode == 'replace':
            self.kps = new_kps
            summary['added'] = len(new_kps)

        elif mode in ['append', 'merge']:
            # ä¸ºäº†æ•ˆç‡ï¼Œé¢„å…ˆæ„å»ºç°æœ‰kpidçš„é›†åˆå’Œç´¢å¼•æ˜ å°„
            existing_kpid_set = {kp['kpid'] for kp in self.kps}
            kpid_to_index_map = {kp['kpid']: i for i, kp in enumerate(self.kps)}

            for new_kp in new_kps:
                kpid = new_kp.get('kpid')
                if not kpid:
                    summary['skipped'] += 1
                    continue

                if kpid in existing_kpid_set:
                    if mode == 'append':
                        summary['skipped'] += 1
                    else: # mode == 'merge'
                        idx = kpid_to_index_map[kpid]
                        self.kps[idx] = new_kp
                        summary['updated'] += 1
                else:
                    self.kps.append(new_kp)
                    summary['added'] += 1
        else:
            raise ValueError(f"æœªçŸ¥çš„å¯¼å…¥æ¨¡å¼: '{mode}'")

        # 3. ä¿å­˜å¹¶é‡å»ºç´¢å¼•
        self._save_database()
        self._build_index()

        summary['total'] = len(self.kps)
        return summary

# --- ä»¥ä¸‹æ˜¯ç”¨äºæµ‹è¯•çš„ä»£ç  ---
if __name__ == "__main__":
    # --- æµ‹è¯•è®¾ç½® ---
    BASE_DATA = [
        {"kpid": "BIO-01", "title": "ç”Ÿç‰©çŸ¥è¯†ç‚¹1 (åŸå§‹)", "parentId": "BIO"},
        {"kpid": "BIO-02", "title": "ç”Ÿç‰©çŸ¥è¯†ç‚¹2", "parentId": "BIO"},
    ]
    IMPORT_DATA = [
        {"kpid": "BIO-01", "title": "ç”Ÿç‰©çŸ¥è¯†ç‚¹1 (å·²æ›´æ–°)", "parentId": "BIO"}, #  æ›´æ–°
        {"kpid": "BIO-03", "title": "ç”Ÿç‰©çŸ¥è¯†ç‚¹3 (æ–°å¢)", "parentId": "BIO"}, #  æ–°å¢
    ]
    TEST_DB_PATH = "temp_test_db.json"
    TEST_IMPORT_PATH = "temp_test_import.json"

    def setup_files():
        with open(TEST_DB_PATH, 'w', encoding='utf-8') as f:
            json.dump(BASE_DATA, f)
        with open(TEST_IMPORT_PATH, 'w', encoding='utf-8') as f:
            json.dump(IMPORT_DATA, f)

    def cleanup_files():
        if os.path.exists(TEST_DB_PATH): os.remove(TEST_DB_PATH)
        if os.path.exists(TEST_IMPORT_PATH): os.remove(TEST_IMPORT_PATH)

    # --- æµ‹è¯•å‡½æ•° ---
    def test_replace_mode():
        print("\n--- æµ‹è¯• 'replace' æ¨¡å¼ ---")
        setup_files()
        manager = KnowledgePointManager(TEST_DB_PATH)
        summary = manager.import_from_file(TEST_IMPORT_PATH, mode='replace')

        assert summary['added'] == 2
        assert summary['updated'] == 0
        assert summary['skipped'] == 0
        assert summary['total'] == 2
        assert manager.get_kp_by_id("BIO-02") is None # æ—§æ•°æ®å·²è¢«åˆ é™¤
        print("âœ… 'replace' æ¨¡å¼æµ‹è¯•é€šè¿‡ï¼")
        cleanup_files()

    def test_append_mode():
        print("\n--- æµ‹è¯• 'append' æ¨¡å¼ ---")
        setup_files()
        manager = KnowledgePointManager(TEST_DB_PATH)
        summary = manager.import_from_file(TEST_IMPORT_PATH, mode='append')

        assert summary['added'] == 1      # BIO-03
        assert summary['updated'] == 0
        assert summary['skipped'] == 1    # BIO-01
        assert summary['total'] == 3      # BIO-01, BIO-02, BIO-03
        assert manager.get_kp_by_id("BIO-01")['title'] == "ç”Ÿç‰©çŸ¥è¯†ç‚¹1 (åŸå§‹)" # æœªè¢«æ›´æ–°
        print("âœ… 'append' æ¨¡å¼æµ‹è¯•é€šè¿‡ï¼")
        cleanup_files()

    def test_merge_mode():
        print("\n--- æµ‹è¯• 'merge' æ¨¡å¼ ---")
        setup_files()
        manager = KnowledgePointManager(TEST_DB_PATH)
        summary = manager.import_from_file(TEST_IMPORT_PATH, mode='merge')

        assert summary['added'] == 1      # BIO-03
        assert summary['updated'] == 1    # BIO-01
        assert summary['skipped'] == 0
        assert summary['total'] == 3      # BIO-01, BIO-02, BIO-03
        assert manager.get_kp_by_id("BIO-01")['title'] == "ç”Ÿç‰©çŸ¥è¯†ç‚¹1 (å·²æ›´æ–°)" # å·²è¢«æ›´æ–°
        print("âœ… 'merge' æ¨¡å¼æµ‹è¯•é€šè¿‡ï¼")
        cleanup_files()

    # --- è¿è¡Œæ‰€æœ‰æµ‹è¯• ---
    try:
        test_replace_mode()
        test_append_mode()
        test_merge_mode()
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•ç”¨ä¾‹å‡å·²é€šè¿‡ï¼")
    except AssertionError as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
    finally:
        cleanup_files()